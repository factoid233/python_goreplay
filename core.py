# -*- coding: utf-8 -*-
import argparse
import datetime
import json
import logging.config
import os
import re
import sys
import urllib.parse
import uuid
from multiprocessing import Process, Manager
from typing import Tuple
from urllib import parse

import attr
import httpx
import numpy as np
import pandas as pd
import trio
from jsoncomparison import Compare as JsonCompare

from util.util import get_root_path, read_yaml, is_json_equal, java_token

log_config_path = os.path.join(get_root_path(), 'log_config.yaml')
logging.config.dictConfig(read_yaml(log_config_path))
logger = logging.getLogger(__name__)


class FileParse:
    """
    è§£æå½•åˆ¶çš„æµé‡çš„æ–‡ä»¶æˆDataframe
    """
    br = "ğŸµğŸ™ˆğŸ™‰\n"
    section_set_pass = {'\n', ''}

    def __init__(self, path):
        self.path = path

    def parse_type1(self):
        """
        è§£æåŸå§‹è¯·æ±‚æ•°æ®
        :return:
        """
        df = self._parse_main(path=self.path, _type='1')
        if df.empty:
            logger.warning(f'è§£ææ–‡ä»¶{self.path} ä¸ºç©º,é€€å‡ºç¨‹åº')
            exit(-1)
        return df

    def parse_type2(self):
        """
        è§£æåŸå§‹å“åº”æ•°æ®
        :return:
        """
        df = self._parse_main(path=self.path, _type='2')
        df['host'] = 'server'
        df['remark'] = ''
        if df.empty:
            logger.warning(f'è§£ææ–‡ä»¶{self.path} ä¸ºç©º,é€€å‡ºç¨‹åº')
            exit(-1)
        return df

    def _parse_main(self, path: str, _type: str) -> pd.DataFrame:
        """
        å¾ªç¯æŒ‰è¡Œè¯»å–goræ–‡ä»¶ï¼Œæ”¯æŒè¶…å¤§æ–‡ä»¶è¯»å–
        æ ¼å¼åŒ–æå–ä¿¡æ¯
        @param path:
        @return:
        """
        data = list()
        # è¯»å–æ–‡ä»¶
        with open(path, 'r', encoding='utf-8', errors="ignore") as f:
            section = ""
            for line in f:
                section += line
                if line == self.br:
                    res = self._proc_section(section, _type)
                    if res is not None:
                        data.append(res)
                    # é‡ç½®section
                    section = ""
            res = self._proc_section(section, _type)
            if res is not None:
                data.append(res)
        # å°†æ•°æ®å­˜å‚¨ä¸ºdataframeæ ¼å¼ æ–¹ä¾¿å¤„ç†
        df = pd.DataFrame(data)
        return df

    def _proc_section(self, section, _type):
        if _type == '1':
            return self._proc_section1(section)
        elif _type == '2':
            return self._proc_section2(section)

    def _proc_section1(self, section):
        if section and section[0] == '1':
            post_data = id1 = timestamp = None
            section = section.strip(self.br)

            # å°†post data ä¸ å…¶ä»–å†…å®¹åˆ†å‰²
            body: list = re.split('\r?\n\r?\n', section)
            if len(body) == 2:
                post_data = body[1]
                try:
                    post_data = json.loads(post_data)
                except json.JSONDecodeError:
                    return
            body1 = body[0]
            # æŒ‰è¡Œåˆ†å‰² ç¬¬ä¸€è¡Œæå–è¯·æ±‚id æ—¶é—´æˆ³ æ—¶é—´æˆ³ç²¾ç¡®åº¦ä¸ºçº³ç§’
            body2: list = re.split('\r?\n', body1)
            line1: list = re.split(r'\s', body2[0])
            # æ— è¯·æ±‚id ç›´æ¥è·³è¿‡
            if not (len(line1) >= 3 and line1[0] == '1'):
                return
            _, id1, timestamp, *_ = line1

            # ç¬¬äºŒè¡Œ æå–æå–è¯·æ±‚æ–¹å¼ã€è¯·æ±‚urlã€è¯·æ±‚åè®®
            # æ— ç¬¬äºŒè¡Œæ•°æ®ç›´æ¥è·³è¿‡
            if len(body2) < 2:
                return None
            line2: list = re.split(r'\s', body2[1])
            # æ— è¯·æ±‚æ–¹å¼å’Œè¯·æ±‚å†…å®¹ç›´æ¥è·³è¿‡
            if not (len(line2) == 3):
                return None
            request_method, url, http_version = line2
            # URLè§£æ
            url_parse_result = parse.urlparse(url)
            uri = url_parse_result.path
            get_query = url_parse_result.query
            get_params = parse.parse_qsl(get_query)
            get_params = dict(get_params)

            # å‰©ä½™ headers æå–
            headers = dict()
            for item in body2[2:]:
                item2 = [item1.strip() for item1 in item.split(':')]
                if len(item2) == 2:
                    headers[item2[0]] = item2[1]
            res_dict = dict(id1=id1, timestamp=timestamp, request_method=request_method, uri=uri,
                            get_params=get_params, post_data=post_data, headers=headers, http_version=http_version)
            return res_dict
        elif section and section[0] in ('2', '3',) or section in self.section_set_pass:
            return None
        else:
            logger.warning(f'goreplay æ–‡ä»¶æœ‰è¯¯,type 1è¯»å–é”™è¯¯,error detail:\n{section}')
            return None

    def _proc_section2(self, section):
        if section and section[0] == '2':
            response = id1 = timestamp = None
            section = section.strip(self.br)

            # å°†å“åº”ç»“æœ ä¸ å…¶ä»–å†…å®¹åˆ†å‰²
            body: list = re.split('\r?\n\r?\n', section)
            if len(body) == 2:
                response: str = body[1]
                # å¤„ç†å¼‚å¸¸çš„response,æ„å¤–å¤šå‡ºä¸¤è¡Œ
                if '\n' in response:
                    response_split = response.split('\n')
                    if len(response_split) > 2:
                        response = response.split('\n')[1]
            # body1 ä¸ºé™¤å“åº”ç»“æœå¤–çš„æ‰€æœ‰ä¿¡æ¯
            body1_text = body[0]
            # æŒ‰è¡Œåˆ†å‰² ç¬¬ä¸€è¡Œæå–è¯·æ±‚id æ—¶é—´æˆ³ æ—¶é—´æˆ³ç²¾ç¡®åº¦ä¸ºçº³ç§’
            body1: list = re.split('\r?\n', body1_text)
            line1: list = re.split(r'\s', body1[0])
            # æ— è¯·æ±‚id ç›´æ¥è·³è¿‡
            if not len(line1) >= 3:
                return None
            _type, id1, timestamp, *_ = line1

            # ç¬¬äºŒè¡Œ æå– è¯·æ±‚åè®® å’Œå“åº”codeç 
            # æ— ç¬¬äºŒè¡Œç›´æ¥è·³è¿‡
            if len(body1) < 2:
                return None
            line2: list = re.split(r'\s', body1[1])
            # æ— è¯·æ±‚æ–¹å¼å’Œè¯·æ±‚å†…å®¹ç›´æ¥è·³è¿‡
            http_version, http_code, *_ = line2
            # response headerè§£æ
            response_headers = dict()
            for item in body1[2:]:
                item2 = [item1.strip() for item1 in re.split(r':\s', item)]
                if len(item2) == 2:
                    response_headers[item2[0]] = item2[1]
            res_dict = dict(id1=id1, timestamp=timestamp, http_code=http_code, response=response,
                            http_version=http_version, response_headers=response_headers)
            return res_dict
        elif section and section[0] in ('1', '3') or section in self.section_set_pass:
            return None
        else:
            logger.warning(f'goreplay æ–‡ä»¶æœ‰è¯¯,type 2è¯»å–é”™è¯¯ï¼Œerror detail:\n{section}')
            return None


class ReplayPrepare:
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.process_other()
        logger.info(f'å…±æ”¶é›†è¯·æ±‚ {self.df.shape[0]} ä¸ª')

    def execute_rules(self, **kwargs):
        rule_keys = ('replace_dict', 'delete_uri', 'filter_needed_uri')
        for key, value in kwargs.items():
            if key in rule_keys:
                getattr(self, f'rule_{key}')(value)

    def rule_replace_dict(self, args: dict = None):
        """
        æ ¹æ®è¯·æ±‚å‚æ•°ä¸­key,æ›¿æ¢keyå¯¹åº”çš„valueå€¼
        getå‚æ•°å’Œpostå‚æ•°å‡æ›¿æ¢
        :return:
        """
        if args is not None and isinstance(args, dict):

            def func(line):
                for key, value in args.items():
                    if isinstance(line, dict) and key in line:
                        line[key] = value
                return line

            def func_header(line: dict):
                if isinstance(line, dict):
                    for key, value in line.copy().items():
                        if key in ('content-length', 'Content-Length'):
                            line.pop(key)
                return line

            # æ ¹æ®æ‰€ç»™å‚æ•° æ›¿æ¢get æˆ–è€…postè¯·æ±‚ä¸­çš„ key value
            self.df['get_params'] = self.df['get_params'].map(func)
            self.df['post_data'] = self.df['post_data'].map(func)
            # å–å‡ºè¯·æ±‚headerä¸­çš„é•¿åº¦å­—æ®µ ä¼šæŠ¥é”™
            self.df['headers'] = self.df['headers'].map(func_header)

    def rule_delete_uri(self, args: list = None):
        if args is not None and isinstance(args, list):
            delete_indexs = self.df[self.df.apply(lambda x: True if x['uri'] in args else False, axis=1)].index
            self.df.drop(index=delete_indexs, inplace=True)

    def rule_filter_needed_uri(self, args: list = None):
        if args is not None and isinstance(args, list):
            delete_index = self.df[self.df.apply(lambda x: True if x['uri'] not in args else False, axis=1)].index
            self.df.drop(index=delete_index, inplace=True)

    def process_timestamp(self, speed):
        """
        å¤„ç†æ—¶é—´æˆ³ï¼Œå®ç°è¯·æ±‚å€é€Ÿ
        @param speed:   2ï¼š2å€é€Ÿå›æ”¾    0.5ï¼š0.5å€é€Ÿå›æ”¾
        @return:
        """
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ•°å­—
        self.df['timestamp'] = pd.to_numeric(self.df['timestamp'])
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºdatetime å¯¹è±¡
        self.df['timestamp'] = pd.to_datetime(self.df['timestamp'])
        # æ—¶é—´æˆ³ä»å°åˆ°å¤§æ’åº
        self.df.sort_values(by=['timestamp'], inplace=True)
        # è®¡ç®— sleepçš„ç§’æ•°
        self.df['sleep'] = (self.df['timestamp'] - self.df['timestamp'].min()).map(lambda x: x.total_seconds())
        # å®ç°å€é€Ÿ
        self.df['sleep'] = self.df['sleep'] / speed
        logger.info(f"å…±éœ€è¿è¡Œ{self.df['sleep'].max() / 60} åˆ†é’Ÿ")

    def process_other(self):
        """
        å¤„ç†headersä¸­çš„Content-Lengthé•¿åº¦é—®é¢˜
        :return:
        """

        def func_header(line: dict):
            if isinstance(line, dict):
                for key, value in line.copy().items():
                    if key in ('content-length', 'Content-Length'):
                        line.pop(key)
            return line

        self.df['headers'] = self.df['headers'].map(func_header)


class ReplayRun:
    def __init__(self, df: pd.DataFrame):
        self.df = df

    async def _send_request_one(self, client: httpx.AsyncClient, host, index, line: pd.Series, total: int):
        """
        åç¨‹å‘é€å•ä¸ªè¯·æ±‚
        @param client:
        @param host:
        @param index:
        @param line:
        @return:
        """
        # self.logger.debug(line['sleep'])
        # é˜»å¡ç›¸åº”çš„æ—¶é—´ï¼Œä½¿è¯·æ±‚æŒ‰ç…§åŸå§‹æ—¶é—´çº¿å‘é€è¯·æ±‚
        await trio.sleep(line['sleep'])

        http_version = line['http_version'].split('/')[0].lower()
        url = http_version + '://' + host + line['uri']

        current = datetime.datetime.now().isoformat()
        response = "null"
        remark = ""
        try:
            if line['request_method'] == 'GET':
                response = await client.get(url=url, params=line['get_params'], headers=line['headers'])
            elif line['request_method'] == 'POST':
                response = await client.post(url=url, params=line['get_params'], json=line['post_data'],
                                             headers=line['headers'])
            response.raise_for_status()
            logger.debug(f"|-- {url}\n\t{response.text}")
        except httpx.TimeoutException as exc:
            remark = "{}".format(client.timeout)
        except httpx.HTTPStatusError as exc:
            response = exc.response
            remark = f"Error response {exc.response.status_code} while requesting {exc.request.url!r}."
        except httpx.HTTPError as exc:
            remark = sys.exc_info()[0].__doc__.strip()
        finally:
            if remark:
                logger.error(remark)

        # æ·»åŠ è¯·æ±‚ä¿¡æ¯
        self.df.loc[index, 'host'] = host
        self.df.loc[index, 'created_time'] = current
        self.df.loc[index, 'response_obj'] = response
        self.df.loc[index, 'remark'] = remark

    async def _send_requests(self, host: str, timeout: int):
        """
        åç¨‹å¹¶å‘å‘é€è¯·æ±‚
        @param host:
        @param timeout:
        @return:
        """
        async with httpx.AsyncClient(timeout=timeout) as client:
            async with trio.open_nursery() as nursery:
                for index, line in self.df.iterrows():
                    nursery.start_soon(self._send_request_one, client, host, index, line, self.df.shape[0])

    def send_requests(self, host: str, timeout: int):
        trio.run(self._send_requests, host, timeout)
        logger.info('replay_run success')


class ReplayPost:
    def __init__(self, df: pd.DataFrame):
        self.df = df

    def process_response(self):
        """
        åå¤„ç†ä¸€äº›reponseä¿¡æ¯
        @return:
        """
        self.df['http_code'] = self.df['response_obj'].map(
            lambda x: x.status_code if isinstance(x, httpx.Response) and x else "null")
        self.df['elapsed_time'] = self.df['response_obj'].map(
            lambda x: x.elapsed.total_seconds() if isinstance(x, httpx.Response) and x else 0)
        self.df['response'] = self.df['response_obj'].map(
            lambda x: x.text if isinstance(x, httpx.Response) and x else x)

        self.df['get_params'] = self.df['get_params'].map(urllib.parse.urlencode)
        # self.df['payload'] = self.df.apply(axis=1,
        #                                    func=lambda x: x['get_params'] if x['request_method'] == 'GET'
        #                                    else x['post_data'])
        logger.info(f'å…±å‘é€è¯·æ±‚ {self.df.shape[0]} ä¸ª')


class ReplayOneHost:
    def __init__(self, gor_path: str, host: str, speed: float = 1, timeout: int = 5, rules=None, *args, **kwargs):
        if rules is None:
            rules = {}
        self.gor_path = gor_path
        self.host = host
        self.speed = speed
        self.timeout = timeout
        self.rules = rules
        self._df = pd.DataFrame()

        self.file_parse = None
        self.replay_prepare = None
        self.replay_run = None
        self.replay_post = None

    @property
    def df(self):
        return self._df

    def _run(self):
        # åˆå§‹åŒ–
        self.file_parse = FileParse(self.gor_path)
        self._df = self.file_parse.parse_type1()
        self.replay_prepare = ReplayPrepare(self._df)
        self.replay_run = ReplayRun(self._df)
        self.replay_post = ReplayPost(self._df)

        # æ‰§è¡Œæµç¨‹
        self.replay_prepare.execute_rules(**self.rules)
        self.replay_prepare.process_timestamp(self.speed)
        self.replay_run.send_requests(host=self.host, timeout=self.timeout)
        self.replay_post.process_response()

    @classmethod
    def run(cls, **kwargs):
        instance = cls(**kwargs)
        instance._run()
        return instance


class ReplayCompare:
    def __init__(self, res_host: list):
        self.res_host = res_host

    def str_to_json(self, _str):
        try:
            _obj = json.loads(_str)
        except Exception:
            _obj = _str
        return _obj

    def _is_pass(self, resp1, resp2, compare_rules: dict = None):
        """
        æ¯”è¾ƒå•ä¸ªå“åº”ç»“æœæ˜¯å¦ä¸€è‡´
        @param resp1:
        @param resp2:
        @param compare_rules:
        @return:
        """
        resp1 = self.str_to_json(resp1)
        resp2 = self.str_to_json(resp2)
        if 'compare_all_equal' in compare_rules.keys():
            is_pass = self._compare_all_equal(resp1, resp2, ignores=compare_rules.get('compare_all_equal'))
            return is_pass
        if 'compare_jsonpath' in compare_rules.keys():
            return
        else:
            is_pass = self._compare_all_equal(resp1, resp2, ignores=None)
            return is_pass

    def _compare_all_equal(self, resp1, resp2, ignores: list = None):
        """
        æ¯”è¾ƒå•ä¸ªå“åº”ç»“æœæ˜¯å¦ä¸€è‡´
        {"compare_all_equal":{"ignore":""}}
        @param resp1:
        @param resp2:
        @return:
        """
        if ignores is None:
            ignores = []
        is_pass = is_json_equal(resp1, resp2, ignores=ignores)

        if isinstance(resp1, str) or isinstance(resp2, str):
            is_pass = False
        elif not (resp1 and resp2):
            is_pass = False
        elif "null" in resp1 or "null" in resp2:
            is_pass = False
        return is_pass

    def _compare_jsonpath(self, resp1, resp2, args: dict):
        """

        :param resp1:
        :param resp2:
        :param args:{"/cs/vhis/accident/query":}
        :return:
        """

    def _compare_data(self, compare_rules=None) -> pd.DataFrame:
        """
        æ¯”è¾ƒä¸¤å°æœåŠ¡å™¨çš„å“åº”ç»“æœ
        @return:
        """
        host1: Tuple[str, pd.DataFrame] = self.res_host[0]
        host2: Tuple[str, pd.DataFrame] = self.res_host[1]
        df1: pd.DataFrame = host1[1]
        df2: pd.DataFrame = host2[1]
        # å–ä¸¤ä¸ªrequest_idçš„å¹¶é›†
        df1.set_index('id1', inplace=True)
        df2.set_index('id1', inplace=True)
        id1s = set(df1.index) | set(df2.index)
        df = pd.DataFrame(columns=df1.columns)
        for id1 in id1s:
            if id1 in df1.index and id1 in df2.index:
                df.at[id1,
                      ['request_method', 'uri', 'get_params', 'post_data', 'headers', 'created_time', 'remark']] \
                    = df1.loc[id1,
                              ['request_method', 'uri', 'get_params', 'post_data', 'headers', 'created_time', 'remark']]
                # åˆå¹¶ä¸¤ä¸ªç›¸åŒçš„å­—æ®µä¸ºä¸€ä¸ª
                for item in ('host', 'http_code', 'response', 'elapsed_time', 'remark'):
                    if item == "response":
                        # å°†responseåˆå¹¶æˆäºŒå…ƒåˆ—è¡¨
                        df.at[id1, item] = [self.str_to_json(df1.loc[id1, item]), self.str_to_json(df2.loc[id1, item])]
                    else:
                        _map_list = [i for i in (df1.loc[id1, item], df2.loc[id1, item]) if i]
                        df.at[id1, item] = "|".join(map(str, _map_list))

                is_pass = self._is_pass(df1.loc[id1, 'response'], df2.loc[id1, 'response'], compare_rules=compare_rules)
                df.loc[id1, 'is_pass'] = "pass" if is_pass else "fail"
        logger.info('æ¯”è¾ƒ done. ')
        return df

    @classmethod
    def compare_data(cls, res_host, compare_rules=None) -> pd.DataFrame:
        return cls(res_host)._compare_data(compare_rules)


class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return super(NpEncoder, self).default(obj)


@attr.s
class Storage:
    df = attr.ib(type=pd.DataFrame)

    def _generate_file_name(self):
        return datetime.datetime.now().strftime('Replay%Y%m%d%H%M%S')

    @classmethod
    def generate_compare_json(cls, x: list):
        """
        å°†ä¸¤ä¸ªå¯¹æ¯”json,åˆæˆä¸€ä¸ªç¾åŒ–è¾“å‡º
        {
        "project": {
            "version": {
                "_message": "Types not equal. Expected: <str>, received: <float>",
                "_expected": "str",
                "_received": "float"
            },
            "license": {
                "_message": "Values not equal. Expected: <MIT>, received: <Apache 2.0>",
                "_expected": "MIT",
                "_received": "Apache 2.0"
            },
            "language": {
                "versions": {
                    "_length": {
                        "_message": "Lengths not equal. Expected <2>, received: <1>",
                        "_expected": 2,
                        "_received": 1
                    },
                    "_content": {
                        "0": {
                            "_message": "Value not found. Expected <3.5>",
                            "_expected": 3.5,
                            "_received": null
                        }
                    }
                }
            }
        },
        "os": {
            "_message": "Key does not exists. Expected: <os>",
            "_expected": "os",
            "_received": null
        }
        }
        :param x:
        :return:
        """
        expected, actual = x
        diff = JsonCompare().check(expected, actual)
        return json.dumps(diff, ensure_ascii=False)

    @classmethod
    def response_handle(cls, x: list):
        """
        ç¾åŒ–reponseexcelæ˜¾ç¤º
        :param x:
        :return:
        """
        x1, x2 = x
        x1 = json.dumps(x1, ensure_ascii=False, cls=NpEncoder)
        x2 = json.dumps(x2, ensure_ascii=False, cls=NpEncoder)
        return f"{x1}\n\n{'=' * 50}\n\n{x2}"

    def _flush_to_csv(self):
        """
        å†™å…¥åˆ°csv
        @return:
        """
        df: pd.DataFrame = self.df.loc[lambda x: x['is_pass'] == 'fail']
        df = df.sort_values('uri')

        df['response_compare_json'] = df['response'].map(self.generate_compare_json)
        df['response'] = df['response'].map(self.response_handle)
        # é€‰æ‹©éƒ¨åˆ†å­—æ®µå­˜å‚¨
        df = df[
            ['uri', 'is_pass', 'request_method', 'host', 'get_params', 'post_data', 'http_code', 'response',
             'response_compare_json', 'elapsed_time', 'remark', 'created_time']].copy()
        # é‡ç½®ç´¢å¼•
        df.reset_index(inplace=True)
        file_dir = os.path.join(get_root_path(), 'output')
        file_name = '{}.csv'.format(self._generate_file_name())
        if not os.path.exists(file_dir):
            os.makedirs(file_dir)
        file_path = os.path.join(file_dir, file_name)
        if not df.empty:
            # é‡åˆ°ä¹±ç æ›¿æ¢æˆ ï¼Ÿï¼Ÿ
            logger.info('å¼€å§‹å†™å…¥...')
            df.to_csv(file_path, index=True, encoding='gbk', errors='replace', mode='a',
                      chunksize=10000)
            logger.info(f'ç”Ÿæˆç»“æœæ–‡ä»¶{file_path}')
        else:
            logger.info('æ— ç»“æœæ–‡ä»¶ç”Ÿæˆï¼Œæ— å¤±è´¥')

    @classmethod
    def flush_to_csv(cls, df):
        cls(df)._flush_to_csv()


class ReplayMain:
    res_host = []
    result_compare_df = None

    @classmethod
    def replay_main(cls):
        ins = cls()
        kwargs = ins._load_args_config(args=None)
        ins.replay_run(**kwargs)

    def replay_run(self, gor_path, host1: str, rules: dict, speed: float = 1, timeout=5, host2: str = None):
        """

        :param gor_path:
        :param host1:
        :param rules: {'replace_dict':'æ›¿æ¢è¯·æ±‚å‚æ•°', 'delete_uri':'è¿‡æ»¤url','ignore':'æ¯”è¾ƒæ—¶å¿½ç•¥ç›¸å…³å­—æ®µ'}
        :param speed:
        :param timeout:
        :param host2:
        :return:
        """
        if host2 is None:
            self.replay_one_host(gor_path, host1, rules, speed, timeout)
        else:
            self.replay_two_host(gor_path, host1, host2, rules, speed, timeout)

    def replay_two_host(self, gor_path, host1: str, host2: str, rules: dict, speed: float = 1, timeout=5):
        self._run_replay(gor_path=gor_path, hosts=[host1, host2], rules=rules, speed=speed, timeout=timeout)
        self._replay_common(rules)

    def replay_one_host(self, gor_path, host1: str, rules: dict, speed: float = 1, timeout=5):
        self._run_replay(gor_path=gor_path, hosts=[host1], rules=rules, speed=speed, timeout=timeout)
        if len(self.res_host) == 0:
            exit(-1)
        self.res_host.append((self.generate_batch(), FileParse(gor_path).parse_type2()))
        self._replay_common(rules)

    def _replay_common(self, rules):
        self.result_compare_df = ReplayCompare.compare_data(self.res_host, compare_rules=rules)
        Storage.flush_to_csv(self.result_compare_df)

    def generate_batch(self):
        batch = uuid.uuid1().hex
        return batch

    def _load_args_config(self, args):
        return vars(self._get_args(args))

    def _get_args(self, args):
        parser = argparse.ArgumentParser(
            description='python goreplay'
        )
        parser.add_argument(
            '-p', '--path',
            action='store',
            dest='gor_path',
            required=True,
            metavar='/mnt/d/Projects/Python/api_test/src/cases/goreplay_replay/20201224.log',
            help='goreplay æµé‡å›æ”¾çš„ç»å¯¹è·¯å¾„'
        )
        parser.add_argument(
            '-h1', '--host1',
            action='store',
            dest='host1',
            required=True,
            metavar='127.0.0.1:8080',
            help='æµé‡å›æ”¾çš„ipåœ°å€å¸¦ç«¯å£å·'
        )
        parser.add_argument(
            '-h2', '--host2',
            action='store',
            dest='host2',
            default=None,
            metavar='127.0.0.1:8080',
            help='æµé‡å›æ”¾çš„ipåœ°å€å¸¦ç«¯å£å·'
        )
        parser.add_argument(
            '-r', '--rules',
            action='store',
            type=json.loads,
            default={},
            dest='rules',
            help="""{"replace_dict":{"æ›¿æ¢è¯·æ±‚å‚æ•°":""}, "delete_uri":["è¿‡æ»¤url"],"ignore":["æ¯”è¾ƒæ—¶å¿½ç•¥ç›¸å…³å­—æ®µkey"]}"""
        )
        parser.add_argument(
            '-v', '--speed',
            action='store',
            type=float,
            dest='speed',
            default=1,
            metavar='2.5',
            help='å›æ”¾å€é€Ÿ'
        )
        parser.add_argument(
            '-t', '--timeout',
            action='store',
            dest='timeout',
            default=5,
            help='è¶…æ—¶æ—¶é—´ ç§’',
            metavar='5'
        )
        # args - è¦è§£æçš„å­—ç¬¦ä¸²åˆ—è¡¨ã€‚ é»˜è®¤æƒ…å†µä¸‹Noneæ˜¯ä» sys.argv è·å–ã€‚
        res = parser.parse_args(args)
        return res

    def _run_replay_thread(self, **kwargs):
        """
        å•ä¸ªçº¿ç¨‹å›æ”¾
        @param gor_file_path:
        @param host:
        @param replace_args:
        @param speed:
        @param timout:
        @return:
        """
        res = ReplayOneHost.run(**kwargs)
        kwargs['share'][self.generate_batch()] = res.df.to_json()

    def _run_replay(self, **kwargs):
        """
        å›æ”¾å¤šå°æœåŠ¡å™¨
        ä¸€å°æœåŠ¡å™¨ä¸€ä¸ªè¿›ç¨‹
        """
        ts = []
        with Manager() as manager:
            d = manager.dict()
            for host in kwargs.pop('hosts'):
                kwargs1 = kwargs.copy()
                kwargs1['host'] = host
                kwargs1['share'] = d
                t = Process(target=self._run_replay_thread,
                            kwargs=kwargs1)
                t.start()
                ts.append(t)
            for t in ts:
                t.join()
            for key, value in d.items():
                self.res_host.append((key, pd.read_json(value)))


if __name__ == '__main__':
    # ReplayMain.replay_main()
    path = r'E:\dingding\pubtest_web.log'
    # path = r'/home/yxgao/Downloads/vin_request_20210428_small.log'
    rules1 = {"filter_needed_uri":
                  ["/cs/vhis/accident/query", "/cs/vhis/accident/analysis", "/cs/vhis/eval",
                   "/cs/vhis/analysis", "/cs/vhis/condition/query"]}
    rules2 = {'replace_dict': {"user": "test",
                               "channel": "test",
                               "client_user": "test",
                               "client_channel": "test",
                               "token": java_token()}}
    ReplayMain().replay_run(gor_path=path, host1='172.16.2.2:9455', rules={},
                            speed=3)
    # x1 = FileParse(path)
    # x1.parse_type1()
    # ReplayOneHost.run(gor_path=path,
    #                   host='118.190.235.150:5027',
    #                   compare_rules={
    #                       'replace_dict': {
    #                           "user": "test",
    #                           "channel": "test",
    #                           "client_user": "test",
    #                           "client_channel": "test",
    #                           "token": java_token()
    #                       },
    #                       'filter_needed_uri': ["/cs/vhis/accident/query", "/cs/vhis/accident/analysis",
    #                                             "/cs/vhis/eval", "/cs/vhis/analysis", "/cs/vhis/condition/query"]
    #                   },
    #                   )
    # x1 = ReplayMain()
    # x1.replay_one_host(gor_path=path,
    #                    host1='118.190.235.150:5024',
    #                    compare_rules={
    #                        'replace_dict': {
    #                            "user": "test",
    #                            "channel": "test",
    #                            "client_user": "test",
    #                            "client_channel": "test",
    #                            "token": java_token()
    #                        },
    #                        'delete_uri': ['/actuator/prometheus']
    #                    }, )
